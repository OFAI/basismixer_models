#!/usr/bin/env python

import argparse
import json
import logging
import os

logging.basicConfig(level=logging.INFO)

import numpy as np

from partitura import load_musicxml, load_match
from partitura.score import expand_grace_notes, remove_grace_notes
from partitura.musicanalysis import make_note_feats
from basismixer.utils import (pair_files,
                              get_unique_onset_idxs,
                              notewise_to_onsetwise,
                              save_pyc_bz,
                              load_pyc_bz)

from basismixer.performance_codec import get_performance_codec

import sys
sys.setrecursionlimit(100000) # 10000 is an example, try with different values

LOGGER = logging.getLogger(__name__)

CONFIG = dict(
    basis_functions=['polynomial_pitch_feature',
                     'loudness_direction_feature',
                     'tempo_direction_feature',
                     'articulation_feature',
                     'duration_feature',
                     # my_feature,
                     # 'grace_feature',
                     'slur_feature',
                     'fermata_feature',
                     # 'metrical_feature'
                     'metrical_strength_feature',
                     'time_signature_feature',
                     'relative_score_position_feature'
         ])

def cache_score_parts(mxml_dir, part_dir='/tmp', validate=True):
    if not os.path.exists(part_dir):
        os.mkdir(part_dir)

    not_loaded = []
    invalid_parts = []
    validate = True
    for f in os.listdir(mxml_dir):
        path = os.path.join(mxml_dir, f)
        if os.path.isfile(path) and ('.xml' in path or '.musicxml' in path):
            # try:
            name = os.path.basename(os.path.splitext(path)[0])
            out_part = os.path.join(part_dir, name + '.pyc.bz')
            if not os.path.exists(out_part):
                LOGGER.info('Caching score {0}'.format(path))
                part = load_musicxml(path)
                save_pyc_bz(part, out_part)

                if validate:
                    saved_part = load_pyc_bz(out_part)
                    if not np.all(part.note_array == saved_part.note_array):
                        invalid_parts.append(path)
            # except:
            #     LOGGER.info('Invalid file {0}'.format(path))
            #     not_loaded.append(path)

    with open(os.path.join(part_dir, 'invalid_parts.txt'), 'w') as f:
        f.write('\n'.join(invalid_parts))

    with open(os.path.join(part_dir, 'not_loaded.txt'), 'w') as f:
        f.write('\n'.join(not_loaded))

    return not_loaded, invalid_parts


def make_dataset_score():
    parser = argparse.ArgumentParser('Create a dataset')
    parser.add_argument('part_dir',
                        help=('Path to the score parts in compressed pickle format. '
                              'If the mxml-folder is provided, the parts will be cached in this folder.'))

    parser.add_argument('bf_dir',
                        help=('Directory to store the basis functions in compressed pickle format'),)

    parser.add_argument('--mxml-dir',
                        help='Path to the scores in MusicXML format',
                        default=None)
    parser.add_argument('--config',
                        help='Config file for specifying basis functions in JSON format',
                        default=None)
    parser.add_argument('--use-gracenotes',
                        help='Expand grace notes (otherwise, they are removed)',
                        action='store_true', default=False)

    args = parser.parse_args()

    if not os.path.exists(args.bf_dir):
        os.mkdir(args.bf_dir)

    if not os.path.exists(args.part_dir):
        os.mkdir(args.part_dir)

    if args.config is None:
        args.config = CONFIG
    else:
        args.config = json.load(open(args.config))

    basis_functions = args.config['basis_functions']

    if os.path.exists(os.path.join(args.part_dir, 'invalid_parts.txt')):
        invalid_parts = list(np.loadtxt(os.path.join(args.part_dir, 'invalid_parts.txt'),
                                        dtype=str))
    else:
        invalid_parts = []
    
    if args.mxml_dir is not None:
        cache_score_parts(args.mxml_dir, part_dir=args.part_dir)

    for f in os.listdir(args.part_dir):
        path = os.path.join(args.part_dir, f)
        name = os.path.basename(path)
        out_fn = os.path.join(args.bf_dir, name)
        if os.path.isfile(path) and '.pyc.bz' in path and path not in invalid_parts:

            if not os.path.exists(out_fn):

                LOGGER.info('Computing basis functions for {0}'.format(path))


                part = load_pyc_bz(path)
                if args.use_gracenotes:
                    LOGGER.info('Expanding grace notes')
                    expand_grace_notes(part)
                else:
                    LOGGER.info('Remove grace notes')
                    remove_grace_notes(part)

                basis, bf_names = make_note_feats(part, basis_functions)
                save_pyc_bz(dict(part=part,
                                 basis=basis,
                                 bf_names=bf_names),
                            out_fn)

def make_dataset_performance():
    parser = argparse.ArgumentParser('Cache dataset of performances')
    parser.add_argument('match_dir',
                        help='Path to the match files')
    parser.add_argument('alignment_dir',
                        help='Path to store the alignments in compressed pickle format')
    parser.add_argument('--quirks',
                        help='For Magaloff/Zeilinger dataset',
                        action='store_true', default=False)

    args = parser.parse_args()

    if not os.path.exists(args.alignment_dir):
        os.mkdir(args.alignment_dir)

    not_loaded = []
    for f in os.listdir(args.match_dir):
        path = os.path.join(args.match_dir, f)

        out_fn = os.path.join(args.alignment_dir, os.path.basename(os.path.splitext(path)[0]) + 'pyc.bz') 

        if not os.path.exists(out_fn) and '.pyc.bz' in path:

            LOGGER.info('Processing {0}'.format(path))
            ppart, alignment = load_match(path, first_note_at_zero=True)
            if args.quirks:
                for n in alignment:
                    if n['label'] == 'match':
                        n['score_id'] = n['score_id'].split('-')[0]

            save_pyc_bz(dict(ppart=ppart,
                             alignment=alignment),
                        out_fn)

    with open(os.path.join(args.alignment_dir, 'not_loaded.txt'), 'w') as f:
        f.write('\n'.join(not_loaded))


if __name__ == '__main__':
    make_dataset_score()
    # make_dataset_performance()
